{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01bb09e9",
   "metadata": {},
   "source": [
    "## Data Preview 1 mock data collections\n",
    "\n",
    "This notebook presents two Data Preview 1 (DP1) mock data collections available in the HATS format. We will walk you through on how to load, preview and work with this data in preparation for the official data release by the Rubin Observatory.\n",
    "\n",
    "#### How was this data generated?\n",
    "\n",
    "The dummy data was generated with a simple [Python script](https://github.com/lsst-sitcom/linccf/blob/main/internal/LSSTCam_init/Mock_DP1_generation.ipynb) that randomizes fields according to partition-level min/max-values.\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "- Which observatory data products were imported?\n",
    "- How to visualize the distribution of the data?\n",
    "- How to visualize the catalog metadata and schema?\n",
    "- How to load individual files with a parquet reader?\n",
    "- How to work with the full catalog with LSDB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293dae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lsdb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Base path to the mock DP1 data\n",
    "base_path = Path(\"/sdf/data/rubin/shared/lsdb_commissioning/mock_dp1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472428d5",
   "metadata": {},
   "source": [
    "#### Which observatory data products were imported?\n",
    "\n",
    "The Data Preview 1 mock data collections were generated based on [DRP v29_0_0_rc5](https://rubinobs.atlassian.net/browse/DM-49865). They contain **DUMMY** data in the same format and with the same data types as the upcoming Rubin Data Preview 1 HATS catalogs.\n",
    "\n",
    "The available collections are `dia_object_collection` and `object_collection`. \n",
    "\n",
    "Each collection contains a main object catalog with time-domain data, and two auxiliary catalogs: a margin cache catalog and an index catalog. The data of interest resides in the main catalogs, named *dia_object_lc* and *object_lc*, and they contain light curve information.\n",
    "\n",
    "- `dia_object_lc` contains data obtained from difference imaging. To create this catalog we joined the data for each *dia_object* with the respective detections in *dia_source* and *dia_forced_source*.\n",
    "\n",
    "- `object_lc` contains data obtained from science imaging. To create this catalog we joined the data for each *object* with the respective detections in *forced_source*. There is no association between *source* and *object*.\n",
    "\n",
    "Powered by [**nested-pandas**](https://nested-pandas.readthedocs.io/en/stable/), the objects' light curve information can be loaded, previewed and processed within a single data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -L 2 $base_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7a4a4",
   "metadata": {},
   "source": [
    "#### How to visualize the distribution of the data?\n",
    "\n",
    "The metadata allows us to visualize the distribution of the data quickly and without any compute. Using the `hats` package we can plot the HEALPix distribution in a mollweide view as well as observe a higher order Multi-Order-Coverage (MOC) map of where the data is in the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hats\n",
    "object_lc = hats.read_hats(base_path / \"object_collection\").main_catalog\n",
    "object_lc.plot_pixels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9dc7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_lc.plot_moc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d56572",
   "metadata": {},
   "source": [
    "#### How to visualize the catalog metadata and schema?\n",
    "\n",
    "The catalogs' metadata and schema (columns and their data types) can be found in their HATS object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e526cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The catalog's arrow schema\n",
    "object_lc.original_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1250bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other provenance information\n",
    "dict(object_lc.catalog_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92e1cb",
   "metadata": {},
   "source": [
    "#### How to load individual files with a parquet reader?\n",
    "\n",
    "We can load individual data files with any parquet-compatible file reader (e.g. `pyarrow.parquet`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75bb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a single file from the object catalog\n",
    "single_parquet = base_path / \"object_collection/object_lc/dataset/Norder=3/Dir=0/Npix=562.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023231f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "partition = pq.read_table(single_parquet)\n",
    "partition.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f6f10",
   "metadata": {},
   "source": [
    "There is a nested column with light curve information (*objectForcedSource*). We recommend **nested-pandas** for reading files in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nested_pandas import read_parquet\n",
    "nested_df = read_parquet(single_parquet)\n",
    "nested_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcdc53d",
   "metadata": {},
   "source": [
    "#### How to work with the full catalog with LSDB?\n",
    "\n",
    "Loading, previewing and creating workflows with HATS data is much simpler with [LSDB](https://docs.lsdb.io/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import lsdb\n",
    "# Read the catalog metadata and visualize it in the notebook\n",
    "object_lc = lsdb.read_hats(base_path / \"object_collection\")\n",
    "object_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7563c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Look at the first 5 rows\n",
    "object_lc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e56f821",
   "metadata": {},
   "source": [
    "A common use case is applying a user-defined function over each partition (pixel) of the catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_per_partition(df, pixel):\n",
    "    \"\"\"This code runs once per partition (pixel).\"\"\"\n",
    "    # Do some processing on the dataframe...\n",
    "    # For example, let's add two new columns with the pixel order and number\n",
    "    df[\"Norder\"] = pixel.order\n",
    "    df[\"Npix\"] = pixel.pixel\n",
    "    return df\n",
    "\n",
    "# This function call is lazily evaluated\n",
    "my_object_lc = object_lc.map_partitions(run_per_partition, include_pixel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f94b1e",
   "metadata": {},
   "source": [
    "The computation is triggered by calling `.compute()`. Here we use `.head()` to only get the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_object_lc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8bf000",
   "metadata": {},
   "source": [
    "Keep in mind that `.compute()` will bring the full result of the catalog into memory. \n",
    "\n",
    "If your catalog is too big to fit in memory or you wish to reuse it later, call `to_hats` and save it to disk:\n",
    "\n",
    "```python\n",
    "my_object_lc.to_hats(\"path_to_my_catalog\", catalog_name=\"name_for_my_catalog\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
