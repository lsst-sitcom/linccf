{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97648c06",
   "metadata": {},
   "source": [
    "# Source clustering\n",
    "\n",
    "This notebook clusters sources from nightly validation to generate object light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9234a23b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:12:57.486831Z",
     "iopub.status.busy": "2025-04-23T20:12:57.486395Z",
     "iopub.status.idle": "2025-04-23T20:13:01.421827Z",
     "shell.execute_reply": "2025-04-23T20:13:01.421319Z",
     "shell.execute_reply.started": "2025-04-23T20:12:57.486814Z"
    }
   },
   "outputs": [],
   "source": [
    "import lsdb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "import lsst.daf.butler as dafButler\n",
    "from lsst.summit.utils import ConsDbClient\n",
    "\n",
    "from dask.distributed import Client\n",
    "from lsdb.core.search import ConeSearch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import astropy.units as u\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b4effb-3884-46eb-afdd-2097e96cae5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:13:01.422697Z",
     "iopub.status.busy": "2025-04-23T20:13:01.422546Z",
     "iopub.status.idle": "2025-04-23T20:13:01.425287Z",
     "shell.execute_reply": "2025-04-23T20:13:01.424886Z",
     "shell.execute_reply.started": "2025-04-23T20:13:01.422682Z"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install git+https://github.com/astronomy-commons/lsdb.git@sean/nested-crossmatch\n",
    "base_output_dir = Path(\"/sdf/data/rubin/shared/lsdb_commissioning/tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c256ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_to_mag(sciFlux):\n",
    "    \"\"\"Move flux into magnitudes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sciFlux : `float`\n",
    "        Science flux\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mag  : `float`\n",
    "        Magnitude\n",
    "    \"\"\"\n",
    "    \n",
    "    mag = u.nJy.to(u.ABmag, sciFlux)\n",
    "    \n",
    "    return mag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabab784",
   "metadata": {},
   "source": [
    "### Query for all recent visits\n",
    "\n",
    "First let's get all the visits from April 18 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5c3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day_obs, end_day_obs = 20250418, 20250423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63231b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T19:51:36.846857Z",
     "iopub.status.busy": "2025-04-23T19:51:36.846300Z",
     "iopub.status.idle": "2025-04-23T19:51:36.862019Z",
     "shell.execute_reply": "2025-04-23T19:51:36.861715Z",
     "shell.execute_reply.started": "2025-04-23T19:51:36.846839Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/sdf/home/n/ncaplar/token-file\", \"r\") as f:\n",
    "    token = f.read()\n",
    "client = ConsDbClient(f\"https://user:{token}@usdf-rsp.slac.stanford.edu/consdb\")\n",
    "visits = client.query(f\"SELECT * FROM cdb_lsstcam.visit1 WHERE day_obs >= {start_day_obs} AND day_obs <= {end_day_obs} and science_program = 'BLOCK-365'\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aeb3dc9-19ac-49a3-beb3-d82093d14487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:09:25.101662Z",
     "iopub.status.busy": "2025-04-23T20:09:25.101447Z",
     "iopub.status.idle": "2025-04-23T20:09:25.104285Z",
     "shell.execute_reply": "2025-04-23T20:09:25.103910Z",
     "shell.execute_reply.started": "2025-04-23T20:09:25.101646Z"
    }
   },
   "outputs": [],
   "source": [
    "num_visits = len(visits)\n",
    "print(f\"Found {num_visits} visits from {start_day_obs} to {end_day_obs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df749b",
   "metadata": {},
   "source": [
    "### Initialize the Butler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391d4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "butler = dafButler.Butler(\"embargo\")  # or your Butler repo path\n",
    "\n",
    "# Query all collections starting with the desired prefix\n",
    "all_collections = list(butler.registry.queryCollections(\"LSSTCam/runs/nightlyValidation/2025*\"))\n",
    "\n",
    "# Filter: keep only those where the final path part ends with '7'\n",
    "filtered_collections = [c for c in all_collections if str(c).strip()[-1] == \"7\"]\n",
    "\n",
    "# Optional: print them sorted\n",
    "for coll in sorted(filtered_collections):\n",
    "    print(coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e152261e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T19:51:55.892629Z",
     "iopub.status.busy": "2025-04-23T19:51:55.892289Z",
     "iopub.status.idle": "2025-04-23T19:51:56.232546Z",
     "shell.execute_reply": "2025-04-23T19:51:56.232030Z",
     "shell.execute_reply.started": "2025-04-23T19:51:55.892586Z"
    }
   },
   "outputs": [],
   "source": [
    "repo = \"embargo\"\n",
    "instrument = \"LSSTCam\"\n",
    "collection_all = \"LSSTCam/runs/nightlyValidation\"\n",
    "butler = dafButler.Butler(repo, collections=filtered_collections, instrument=instrument)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a223f6-4a09-4738-a99c-bb759b8b5a1b",
   "metadata": {},
   "source": [
    "### Create object table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b8fbb9-97d0-48b5-8c78-22d6d130dffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T19:51:57.609209Z",
     "iopub.status.busy": "2025-04-23T19:51:57.608458Z",
     "iopub.status.idle": "2025-04-23T19:51:57.614338Z",
     "shell.execute_reply": "2025-04-23T19:51:57.613870Z",
     "shell.execute_reply.started": "2025-04-23T19:51:57.609190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find visit of best dimm_seeing\n",
    "visits = visits.sort_values(\"dimm_seeing\")\n",
    "visits = visits[~visits[\"dimm_seeing\"].isna()]\n",
    "visit_best_dimm_seeing = visits.iloc[0]\n",
    "visit_best_dimm_seeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00d6ce9-3ab4-481c-979b-378b9d637cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T19:52:52.228546Z",
     "iopub.status.busy": "2025-04-23T19:52:52.228330Z",
     "iopub.status.idle": "2025-04-23T19:52:52.457181Z",
     "shell.execute_reply": "2025-04-23T19:52:52.456689Z",
     "shell.execute_reply.started": "2025-04-23T19:52:52.228531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the name of the collection for the day_obs: 20250418\n",
    "day_obs = visit_best_dimm_seeing[\"day_obs\"]\n",
    "day_collection = butler.registry.queryCollections(f\"LSSTCam/runs/nightlyValidation/{day_obs}*7\")[0]\n",
    "day_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4b87684-f9ed-42e4-ba78-6dd0ca54d465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T19:52:55.684990Z",
     "iopub.status.busy": "2025-04-23T19:52:55.684293Z",
     "iopub.status.idle": "2025-04-23T19:52:57.985126Z",
     "shell.execute_reply": "2025-04-23T19:52:57.984530Z",
     "shell.execute_reply.started": "2025-04-23T19:52:55.684971Z"
    }
   },
   "outputs": [],
   "source": [
    "butler = dafButler.Butler(repo, collections=day_collection, instrument=instrument)\n",
    "object_df = butler.get('single_visit_star', visit=visit_best_dimm_seeing[\"visit_id\"], instrument=instrument).to_pandas()\n",
    "object_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b492e",
   "metadata": {},
   "source": [
    "Let's transform this object dataframe into a HATS catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b94493-3c65-4bfc-b2de-acd4e0e7dc86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:05:41.472721Z",
     "iopub.status.busy": "2025-04-23T20:05:41.472270Z",
     "iopub.status.idle": "2025-04-23T20:05:48.632107Z",
     "shell.execute_reply": "2025-04-23T20:05:48.631535Z",
     "shell.execute_reply.started": "2025-04-23T20:05:41.472702Z"
    }
   },
   "outputs": [],
   "source": [
    "object_cat = lsdb.from_dataframe(object_df)\n",
    "# There is a bug using the from_dataframe output directly:\n",
    "# A workaround is to save the catalog to transient storage and load it back\n",
    "object_cat.to_hats(base_output_dir / \"object\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6edbf455",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cat = lsdb.read_hats(base_output_dir / \"object\")\n",
    "object_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e878076",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cat.plot_pixels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569dfc3",
   "metadata": {},
   "source": [
    "### Query for all sources\n",
    "\n",
    "Let's query the Butler to get the sources for all the visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d932cd57-19c4-4eba-bfe1-38ee19d91a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T19:54:41.247159Z",
     "iopub.status.busy": "2025-04-23T19:54:41.246942Z",
     "iopub.status.idle": "2025-04-23T19:55:31.286432Z",
     "shell.execute_reply": "2025-04-23T19:55:31.285963Z",
     "shell.execute_reply.started": "2025-04-23T19:54:41.247144Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_butler_for_day(day_obs):\n",
    "    day_collection = butler.registry.queryCollections(f\"LSSTCam/runs/nightlyValidation/{day_obs}*7\")[0]\n",
    "    return dafButler.Butler(repo, collections=filtered_collections, instrument=instrument)\n",
    "\n",
    "def _filter_source_df(df):\n",
    "    # Filter non-primary detections\n",
    "    df = df[df['detect_isPrimary']]\n",
    "    # Those with invalid coord_ra\n",
    "    df = df.dropna(subset=[\"coord_ra\"])\n",
    "    # Or the fake detections \n",
    "    df = df[df['sky_source'] == False]\n",
    "    # Cut only to \"i\" band\n",
    "    df = df[df[\"band\"] == \"i\"]\n",
    "    # Reduce number of columns (for efficiency)\n",
    "    return df[[\"ra\",\"dec\",\"sourceId\",\"band\",\"psfFlux\",\"psfFluxErr\"]]\n",
    "\n",
    "def get_sources_for_day(day_visits):\n",
    "    try:\n",
    "        # Initialize butler for current day\n",
    "        day_obs = day_visits[\"day_obs\"].iloc[0]\n",
    "        day_butler = _get_butler_for_day(day_obs)\n",
    "        ids, mjds = day_visits[\"visit_id\"], day_visits[\"exp_midpt_mjd\"]\n",
    "\n",
    "        day_dfs = []\n",
    "        # Get the sources for each visit\n",
    "        for visit_id, visit_mjd in tqdm(zip(ids, mjds)):\n",
    "            try:\n",
    "                df = day_butler.get(\n",
    "                    'single_visit_star', visit=visit_id, instrument=instrument\n",
    "                ).to_pandas()\n",
    "                df = _filter_source_df(df)\n",
    "                if not df.empty:\n",
    "                    df[\"visit_id\"] = visit_id\n",
    "                    df[\"mjd\"] = visit_mjd\n",
    "                    day_dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping visit {visit_id} due to error: {e}\")\n",
    "\n",
    "        print(f\"Loaded {len(day_dfs)} dataframes from {day_collection}\")\n",
    "        return pd.concat(day_dfs, ignore_index=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect only non-empty DataFrames\n",
    "all_dfs = []\n",
    "for _, day_visits in visits.groupby(\"day_obs\"):\n",
    "    df = get_sources_for_day(day_visits)\n",
    "    if df is not None and not df.empty:\n",
    "        all_dfs.append(df)\n",
    "\n",
    "# Concatenate only if there's something to concatenate\n",
    "if all_dfs:\n",
    "    sources_df = pd.concat(all_dfs, ignore_index=True)\n",
    "else:\n",
    "    sources_df = pd.DataFrame()  # Empty fallback\n",
    "\n",
    "sources_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c78f19-3d92-4f7e-afd9-e4f83fc513e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T20:03:41.166435Z",
     "iopub.status.busy": "2025-04-23T20:03:41.166224Z",
     "iopub.status.idle": "2025-04-23T20:03:54.181503Z",
     "shell.execute_reply": "2025-04-23T20:03:54.181022Z",
     "shell.execute_reply.started": "2025-04-23T20:03:41.166419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import with lsdb\n",
    "source_cat = lsdb.from_dataframe(sources_df)\n",
    "# There is a bug using the from_dataframe output directly:\n",
    "# A workaround is to save the catalog to transient storage and load it back\n",
    "source_cat.to_hats(base_output_dir / \"source\", overwrite=True)\n",
    "#source_cat = lsdb.read_hats(base_output_dir / \"source\")\n",
    "#source_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0072a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_cat = lsdb.read_hats(base_output_dir / \"source\")\n",
    "source_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037a546",
   "metadata": {},
   "source": [
    "Let's remove the few sources that are distant from the main cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "700aca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_cat.plot_pixels()\n",
    "cone = ConeSearch(ra=218, dec=-15, radius_arcsec=12*3600)\n",
    "cone.plot(fc=\"#00000000\", ec=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bed0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_cat = source_cat.cone_search(ra=cone.ra, dec=cone.dec, radius_arcsec=cone.radius_arcsec)\n",
    "source_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616f855",
   "metadata": {},
   "source": [
    "### Construct light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb44d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = tempfile.TemporaryDirectory()\n",
    "tmp_dir = tmp_path.name\n",
    "client = Client(n_workers=16, threads_per_worker=1, local_directory=tmp_dir)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9851c1ce-1d89-49c0-b332-27746ba0ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get light curves for the catalog\n",
    "lc_cat = object_cat.crossmatch_nested(source_cat, radius_arcsec=0.2, n_neighbors=num_visits, nested_column_name=\"lc\")\n",
    "lc_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fb89aa5-8b8d-44f9-a173-c6c29dc5a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took roughly 30sec\n",
    "object_lc = lc_cat.reduce(lambda mjd: {\"nobs\": mjd.size}, \"lc.mjd\", meta={\"nobs\": int}, append_columns=True)\n",
    "object_lc = object_lc.query(\"nobs > 10\")\n",
    "object_lc = object_lc.compute()\n",
    "object_lc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d714f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "tmp_path.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f0ea8",
   "metadata": {},
   "source": [
    "### Plot light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da078582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a single light curve\n",
    "lc = object_lc.iloc[10][\"lc\"].sort_values(\"mjd\")\n",
    "lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9a60e2-4a1e-49dd-b1dc-f5ffe1a49b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = {\n",
    "    \"u\": \"#56b4e9\",\n",
    "    \"g\": \"#009e73\",\n",
    "    \"r\": \"#f0e442\",\n",
    "    \"i\": \"#cc79a7\",\n",
    "    \"z\": \"#d55e00\",\n",
    "    \"y\": \"#0072b2\",\n",
    "}\n",
    "\n",
    "def plot_rubin_lc(lc, flux_col, fluxerr_col):\n",
    "    _, ax = plt.subplots()\n",
    "    for band, color in COLORS.items():\n",
    "        band_lc = lc.query(f\"band == '{band}'\")\n",
    "        flux, fluxerr = band_lc[flux_col], band_lc[fluxerr_col]\n",
    "        ax.errorbar(\n",
    "            band_lc[\"mjd\"],\n",
    "            flux,\n",
    "            fluxerr,\n",
    "            fmt=\"o\",\n",
    "            label=band,\n",
    "            color=color,\n",
    "            alpha=1,\n",
    "            markersize=5,\n",
    "            capsize=3,\n",
    "            elinewidth=1,\n",
    "        )\n",
    "    ax.set_xlabel(\"MJD\")\n",
    "    ax.set_ylabel(\"Flux\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend(loc=\"lower right\", fontsize=12)\n",
    "\n",
    "plot_rubin_lc(lc, \"psfFlux\", \"psfFluxErr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02457cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89c44030",
   "metadata": {},
   "source": [
    "# Find RRLyrae from GAIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4ea90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "file_path = \"/sdf/home/n/ncaplar/asu-txt.txt\"\n",
    "\n",
    "# Read lines excluding comments and blank lines\n",
    "with open(file_path, \"r\") as f:\n",
    "    lines = [line.rstrip(\"\\n\") for line in f if not line.startswith(\"#\") and line.strip()]\n",
    "\n",
    "# Find header line (with units) and the next two lines (column names + dashes)\n",
    "for i, line in enumerate(lines):\n",
    "    if \"RAJ2000\" in line and \"(\" in line:\n",
    "        header_index = i\n",
    "        break\n",
    "\n",
    "column_line = lines[header_index ]\n",
    "dash_line = lines[header_index + 1]\n",
    "\n",
    "# Clean column names by splitting on 2+ spaces\n",
    "column_names = re.split(r'\\s{2,}', column_line.strip())\n",
    "\n",
    "# Prepare the data block (after dashed line)\n",
    "data_lines = lines[header_index + 3:]\n",
    "data_text = \"\\n\".join(data_lines)\n",
    "column_names = ['RA', 'DEC', 'Harm', 'Source', 'SolId', 'PF', 'P10', 'gavg', 'agavg', 'agavg2', 'M/H', 'R21G', 'R31G', 'i21G', 'phi31G', 'FundFreq1', 'FundFreq2', 'lass']\n",
    "\n",
    "# Read as fixed-width with correct column names\n",
    "df_RR_Lyrae = pd.read_fwf(StringIO(data_text), header=None, names=column_names)\n",
    "\n",
    "print(\"Column names:\", df_RR_Lyrae.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df042ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_Lyrae_nightly = lsdb.crossmatch(df_RR_Lyrae[['RA','DEC']],object_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c63653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_lc['RA'] = object_lc['coord_ra']\n",
    "object_lc['DEC'] = object_lc['coord_dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "679691ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_lc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21f73365",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_Lyrae_nightly_computed = lsdb.crossmatch(df_RR_Lyrae[['RA','DEC','PF','P10']], object_lc[['RA',\t'DEC','sourceId']]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e889d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_RRLyrae_in_nightly = RR_Lyrae_nightly_computed['sourceId_right'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bad7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RRLyrae_lc = object_lc[object_lc['sourceId'].isin(id_RRLyrae_in_nightly)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04cffa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RR_Lyrae_nightly_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653b8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "RRLyrae_lc.iloc[10]['sourceId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91824039",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_par_for_single_lc = RR_Lyrae_nightly_computed[RR_Lyrae_nightly_computed['sourceId_right'] == RRLyrae_lc.iloc[10]['sourceId']][['PF_left','P10_left']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9436919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mag_errors(sciFlux, sciFluxErr):\n",
    "    \"\"\"Move flux into magnitudes and calculate the error on the magnitude\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sciFlux : `float`\n",
    "        Science flux\n",
    "    sciFluxErr : `float`\n",
    "        Science flux error\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mag, magerr  : `float`, `float`\n",
    "        Magnitude and magnitude error\n",
    "    \"\"\"\n",
    "    \n",
    "    mag = u.nJy.to(u.ABmag, sciFlux)\n",
    "    upper_mag = u.nJy.to(u.ABmag, sciFlux+sciFluxErr)\n",
    "    lower_mag = u.nJy.to(u.ABmag, sciFlux-sciFluxErr)\n",
    "    magErr = -(upper_mag-lower_mag)/2\n",
    "    \n",
    "    return mag, magErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ab1a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mag_errors(lc['psfFlux'].values, lc['psfFluxErr'].values)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68b45fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR_Lyrae_nightly_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bde21081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define sinusoid model: phase in [0, 1]\n",
    "def sinusoid(phase, A, phi0, mean_mag):\n",
    "    return mean_mag + A * np.sin(2 * np.pi * phase + phi0)\n",
    "\n",
    "for i in range(len(RRLyrae_lc)):\n",
    "    row = RRLyrae_lc.iloc[i]\n",
    "    lc = row.lc\n",
    "    source_id = row['sourceId']\n",
    "\n",
    "    # Retrieve period\n",
    "    period_row = RR_Lyrae_nightly_computed[RR_Lyrae_nightly_computed['sourceId_right'] == source_id]\n",
    "    if period_row.empty:\n",
    "        continue\n",
    "\n",
    "    period = period_row['PF_left'].values[0]\n",
    "    if pd.isna(period) and 'P10_left' in period_row.columns:\n",
    "        period = period_row['P10_left'].values[0]\n",
    "    if pd.isna(period):\n",
    "        continue\n",
    "\n",
    "    # Convert flux to magnitude\n",
    "    mag = flux_to_mag(lc['psfFlux'].values)\n",
    "    mag_err = create_mag_errors(lc['psfFlux'].values, lc['psfFluxErr'].values)[1]\n",
    "\n",
    "    # Time and phase\n",
    "    time = lc['mjd'].values\n",
    "    phase = (time % period) / period\n",
    "\n",
    "    # RA/Dec for title\n",
    "    ra = row['coord_ra']\n",
    "    dec = row['coord_dec']\n",
    "\n",
    "    # Fit sinusoid on phase-folded data\n",
    "    valid = np.isfinite(phase) & np.isfinite(mag)\n",
    "    try:\n",
    "        popt, _ = curve_fit(sinusoid, phase[valid], mag[valid],\n",
    "                            p0=[0.5, 0.0, np.nanmean(mag)],\n",
    "                            sigma=mag_err[valid] if mag_err is not None else None,\n",
    "                            absolute_sigma=True)\n",
    "        A_fit, phi0_fit, mean_mag_fit = popt\n",
    "\n",
    "        # For phase-folded panel\n",
    "        phase_model = np.linspace(0, 1, 500)\n",
    "        mag_model_phase = sinusoid(phase_model, A_fit, phi0_fit, mean_mag_fit)\n",
    "\n",
    "        # For time-domain panel: unwrap phase model over time range\n",
    "        t_model = np.linspace(np.min(time), np.max(time), 1000)\n",
    "        phase_t_model = (t_model % period) / period\n",
    "        mag_model_time = sinusoid(phase_t_model, A_fit, phi0_fit, mean_mag_fit)\n",
    "    except Exception as e:\n",
    "        print(f\"Fit failed for sourceId {source_id} â€” {e}\")\n",
    "        continue\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "\n",
    "    # Time-domain plot\n",
    "    axes[0].errorbar(time, mag, yerr=mag_err, fmt='o', markersize=3, alpha=0.7, capsize=3,color='black', label='Observed, i-band')\n",
    "    axes[0].plot(t_model, mag_model_time, 'r--', lw=1, label='Fit')\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].set_xlabel(\"MJD\")\n",
    "    axes[0].set_ylabel(\"Magnitude\")\n",
    "    axes[0].legend(loc='upper right')\n",
    "    # Add space for legend\n",
    "    ymin, ymax = axes[0].get_ylim()\n",
    "    axes[0].set_ylim(ymin - 0.2 * (ymax - ymin), ymax + 0.2 * (ymax - ymin))\n",
    "\n",
    "    # Phase-folded plot\n",
    "    axes[1].errorbar(phase, mag, yerr=mag_err, fmt='o', markersize=3, alpha=0.7,capsize=3,color='black', label='Observed, i-band')\n",
    "    axes[1].plot(phase_model, mag_model_phase, 'r--', lw=1, label='Fit')\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].set_xlabel(\"Phase\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "    axes[1].legend(loc='upper right')\n",
    "    axes[1].set_ylim(ymin - 0.2 * (ymax - ymin), ymax + 0.2 * (ymax - ymin))\n",
    "    \n",
    "    fig.suptitle(f\"RA={ra:.5f}, Dec={dec:.5f} / Period={period:.4f} days\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40209f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203da9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rubin_lc(RRLyrae_lc.iloc[10].lc, \"psfFlux\", \"psfFluxErr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976dce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Compute phase\n",
    "        lc = lc.assign(phase=(lc.midpointMjdTai - lc.midpointMjdTai.loc[lc.psfFlux.idxmax()]) \n",
    "                       % row.Period_nice_obj / row.Period_nice_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52372ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ccd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf48d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
