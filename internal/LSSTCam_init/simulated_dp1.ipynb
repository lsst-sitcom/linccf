{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77f679e",
   "metadata": {},
   "source": [
    "# Simulated HATS DP1\n",
    "\n",
    "This notebook creates a HATS catalog of simulated DP1 data.\n",
    "\n",
    "### Data requirements\n",
    "\n",
    "- Shuffle all the points around by _healpix_29 and assign new radecs based on that;\n",
    "- All other fields can be re-generated within partition-level min/max uniformly;\n",
    "- Boolean can be true/false randomly;\n",
    "- Light curve can have the same length, but should also be twiddled with;\n",
    "- For band, sample from \"ugrizy\" chars;\n",
    "- The object and source IDs, dimensions, and visit are not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f14b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdshealpix\n",
    "import lsdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hats_import.pipeline as runner\n",
    "import tempfile\n",
    "\n",
    "from dask.distributed import Client\n",
    "from hats_import.collection.arguments import CollectionArguments\n",
    "from hats.pixel_math.spatial_index import spatial_index_to_healpix\n",
    "from nested_pandas import NestedDtype\n",
    "from pandas.api.types import (\n",
    "    is_integer_dtype,\n",
    "    is_float_dtype,\n",
    "    is_bool_dtype,\n",
    "    is_string_dtype,\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_nested(df, columns):\n",
    "    \"\"\"Helper function to cast nested columns to the correct type.\"\"\"\n",
    "    return df.assign(\n",
    "        **{\n",
    "            col: df[col].astype(NestedDtype.from_pandas_arrow_dtype(df.dtypes[col]))\n",
    "            for col in columns\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3002cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = tempfile.TemporaryDirectory()\n",
    "tmp_dir = tmp_path.name\n",
    "client = Client(n_workers=16, threads_per_worker=1, local_directory=tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67706b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hats_dir = Path(\"/sdf/data/rubin/shared/lsdb_commissioning/mock_dp1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24deee12",
   "metadata": {},
   "source": [
    "### Mock data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb0adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "default_fixed_columns = [\n",
    "    \"diaObjectId\",\n",
    "    \"nDiaSources\",\n",
    "    \"diaSourceId\",\n",
    "    \"forcedSourceOnDiaObjectId\",\n",
    "    \"objectId\",\n",
    "    \"forcedSourceId\",\n",
    "    \"visit\",\n",
    "    \"tract\",\n",
    "    \"patch\",\n",
    "    \"detector\",\n",
    "]\n",
    "ra_columns = [\"ra\", \"coord_ra\"]\n",
    "dec_columns = [\"dec\", \"coord_dec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03be847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_partition(df, *, nested_columns=[]):\n",
    "    \"\"\"Populates a partition with mock data.\n",
    "\n",
    "    - Integers, floats and timestamps are re-generated within min/max uniformly;\n",
    "    - Boolean columns are assigned True/False values randomly;\n",
    "    - String columns are sampled from the available choices, also randomly;\n",
    "    \"\"\"\n",
    "    if not len(df):\n",
    "        return df\n",
    "    df = mock_positions(df, update_index=True)\n",
    "    fixed_columns = ra_columns + dec_columns + nested_columns + default_fixed_columns\n",
    "    df = mock_base_columns(df, fixed_columns)\n",
    "    return mock_nested_columns(df, nested_columns, fixed_columns)\n",
    "\n",
    "\n",
    "def mock_base_columns(df, fixed_columns=[]):\n",
    "    \"\"\"Generates randomly sampled data for a partition's base fields.\"\"\"\n",
    "    n_samples = len(df)\n",
    "    columns_to_update = [col for col in df.columns if col not in fixed_columns]\n",
    "    for column in columns_to_update:\n",
    "        df[column] = _sample_column(df, column, n_samples)\n",
    "    return df\n",
    "\n",
    "\n",
    "def mock_nested_columns(df, nested_cols, fixed_columns):\n",
    "    \"\"\"Generates randomly sampled data for a partition's nested fields.\"\"\"\n",
    "    for source_col in nested_cols:\n",
    "        flat_sources = df[source_col].nest.to_flat()\n",
    "        mock_sources = mock_positions(flat_sources, update_index=False)\n",
    "        mock_sources = mock_base_columns(mock_sources, fixed_columns)\n",
    "        # Sort re-generated sources by mjd and repack them\n",
    "        mock_sources = mock_sources.sort_values(\"midpointMjdTai\")\n",
    "        df = df.drop(columns=[source_col])\n",
    "        df = df.add_nested(mock_sources, source_col)\n",
    "    return df\n",
    "\n",
    "\n",
    "def mock_positions(df, update_index=True):\n",
    "    \"\"\"Updates _healpix_29 and positional ra/dec coordinates\"\"\"\n",
    "    _healpix_29 = df.index.to_numpy()\n",
    "\n",
    "    # Randomly sample _healpix_29 values for the current partition\n",
    "    min_index = _healpix_29.min()\n",
    "    max_index = _healpix_29.max()\n",
    "    rand_index = rng.integers(min_index, max_index, size=len(df), dtype=np.int64)\n",
    "    ipix = spatial_index_to_healpix(rand_index)\n",
    "    ra, dec = cdshealpix.healpix_to_lonlat(ipix, depth=29)\n",
    "\n",
    "    # When mocking positions for the nested sources the _healpix_29 values\n",
    "    # should be kept. They will be the object's _healpix_29.\n",
    "    if update_index:\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.index = pd.Index(rand_index, name=\"_healpix_29\")\n",
    "\n",
    "    for ra_col in [\"ra\", \"coord_ra\"]:\n",
    "        if ra_col in df.columns:\n",
    "            coords_dtype = df[ra_col].dtype\n",
    "            df[ra_col] = pd.Series(ra.deg, index=df.index, dtype=coords_dtype)\n",
    "    for dec_col in [\"dec\", \"coord_dec\"]:\n",
    "        if dec_col in df.columns:\n",
    "            coords_dtype = df[dec_col].dtype\n",
    "            df[dec_col] = pd.Series(dec.deg, index=df.index, dtype=coords_dtype)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _sample_column(df, column, n_samples):\n",
    "    \"\"\"Samples values for a column of specified type\"\"\"\n",
    "    column_data = df[column].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    _min = column_data.min()\n",
    "    _max = column_data.max()\n",
    "\n",
    "    if pd.isna(_min) or pd.isna(_max):\n",
    "        series = [None] * n_samples\n",
    "    elif is_integer_dtype(column_data):\n",
    "        series = rng.integers(_min, _max + 1, size=n_samples)\n",
    "    elif is_float_dtype(column_data):\n",
    "        series = rng.uniform(_min, _max, size=n_samples)\n",
    "    elif is_bool_dtype(column_data):\n",
    "        series = rng.integers(0, 2, size=n_samples).astype(bool)\n",
    "    elif is_string_dtype(column_data):\n",
    "        possible_strings = (\n",
    "            list(\"ugrizy\") if column == \"band\" else column_data.dropna().unique()\n",
    "        )\n",
    "        series = rng.choice(possible_strings, size=n_samples)\n",
    "    elif column_data.dtype == \"timestamp[ns][pyarrow]\":\n",
    "        series = rng.integers(_min.value, _max.value + 1, size=n_samples)\n",
    "    else:\n",
    "        series = [None] * n_samples\n",
    "\n",
    "    return pd.Series(series, index=column_data.index, dtype=column_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a1f45",
   "metadata": {},
   "source": [
    "### dia_object_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2471eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_object_lc = lsdb.read_hats(\n",
    "    \"/sdf/data/rubin/shared/lsdb_commissioning/hats/v29_0_0_rc5/dia_object_lc\"\n",
    ")\n",
    "dia_object_lc = dia_object_lc.map_partitions(\n",
    "    cast_nested, columns=[\"diaSource\", \"diaObjectForcedSource\"]\n",
    ")\n",
    "dia_object_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_dia_object_lc = dia_object_lc.map_partitions(\n",
    "    mock_partition, nested_columns=[\"diaSource\", \"diaObjectForcedSource\"]\n",
    ")\n",
    "mock_dia_object_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ad796",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_dia_object_lc.to_hats(hats_dir / \"dia_object_lc\", catalog_name=\"dia_object_lc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2473180",
   "metadata": {},
   "source": [
    "### object_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_lc = lsdb.read_hats(\n",
    "    \"/sdf/data/rubin/shared/lsdb_commissioning/hats/v29_0_0_rc5/object_lc\"\n",
    ")\n",
    "object_lc = object_lc.map_partitions(cast_nested, columns=[\"objectForcedSource\"])\n",
    "object_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_object_lc = object_lc.map_partitions(\n",
    "    mock_partition, nested_columns=[\"objectForcedSource\"]\n",
    ")\n",
    "mock_object_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_object_lc.to_hats(hats_dir / \"object_lc\", catalog_name=\"object_lc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7b0605",
   "metadata": {},
   "source": [
    "### Create collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d00030",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\n",
    "    CollectionArguments(\n",
    "        output_artifact_name=\"dia_object_collection\",\n",
    "        new_catalog_name=\"dia_object_lc\",\n",
    "        output_path=hats_dir,\n",
    "        simple_progress_bar=True,\n",
    "    )\n",
    "    .catalog(\n",
    "        catalog_path=hats_dir / \"dia_object_collection\" / \"dia_object_lc\",\n",
    "    )\n",
    "    .add_margin(margin_threshold=5.0, is_default=True)\n",
    "    .add_index(indexing_column=\"diaObjectId\")\n",
    ")\n",
    "runner.pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0514e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\n",
    "    CollectionArguments(\n",
    "        output_artifact_name=\"object_collection\",\n",
    "        new_catalog_name=\"object_lc\",\n",
    "        output_path=hats_dir,\n",
    "        simple_progress_bar=True,\n",
    "    )\n",
    "    .catalog(\n",
    "        catalog_path=hats_dir / \"object_collection\" / \"object_lc\",\n",
    "    )\n",
    "    .add_margin(margin_threshold=5.0, is_default=True)\n",
    "    .add_index(indexing_column=\"objectId\")\n",
    ")\n",
    "runner.pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce078253",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "tmp_path.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
