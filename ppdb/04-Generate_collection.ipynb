{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c615744b",
   "metadata": {},
   "source": [
    "## Generate collection\n",
    "\n",
    "Create DIA Object collection with margin and index on `diaObjectId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a067f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdb\n",
    "import os\n",
    "\n",
    "from dask.distributed import Client\n",
    "from datetime import datetime\n",
    "from hats_import import pipeline_with_client\n",
    "from hats_import import ImportArguments\n",
    "from hats_import.collection.arguments import CollectionArguments\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d36d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the RAW parquet data\n",
    "PPDB_DIR = Path(\"/sdf/scratch/rubin/ppdb/data/lsstcam\")\n",
    "\n",
    "# Paths to the target OUTPUT directories\n",
    "HATS_DIR = Path(os.environ[\"OUTPUT_DIR\"])\n",
    "TMP_DIR = HATS_DIR / \"tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "143dfd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final collection directory.\n",
    "COLLECTION_DIR = HATS_DIR / \"dia_object_collection\"\n",
    "\n",
    "# The collection will contain the most recent\n",
    "# version of data stored with the latest date.\n",
    "DATE_STR = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde65bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Dask Client\n",
    "client = Client(n_workers=16, threads_per_worker=1, local_directory=TMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9604e",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c2051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reimport(input_path):\n",
    "    \"\"\"Reimport the catalog to optimize partitioning, generate alternative\n",
    "    sky maps and set default columns. The resulting catalog is saved to the\n",
    "    working TEMP_DIR and it is named after today's date.\"\"\"\n",
    "    default_columns = \",\".join(\n",
    "        \"\"\"\\\n",
    "        dec\n",
    "        decErr\n",
    "        diaObjectId\n",
    "        ra\n",
    "        raErr\n",
    "        u_psfFluxMean\n",
    "        g_psfFluxMean\n",
    "        r_psfFluxMean\n",
    "        i_psfFluxMean\n",
    "        z_psfFluxMean\n",
    "        y_psfFluxMean\n",
    "        u_psfFluxMeanErr\n",
    "        g_psfFluxMeanErr\n",
    "        r_psfFluxMeanErr\n",
    "        i_psfFluxMeanErr\n",
    "        z_psfFluxMeanErr\n",
    "        y_psfFluxMeanErr\n",
    "        nDiaSources\n",
    "        validityStart\n",
    "        diaSource.apFlux\n",
    "        diaSource.apFluxErr\n",
    "        diaSource.band\n",
    "        diaSource.dec\n",
    "        diaSource.decErr\n",
    "        diaSource.detector\n",
    "        diaSource.diaSourceId\n",
    "        diaSource.isDipole\n",
    "        diaSource.ixx\n",
    "        diaSource.ixxPSF\n",
    "        diaSource.iyy\n",
    "        diaSource.iyyPSF\n",
    "        diaSource.ixy\n",
    "        diaSource.ixyPSF\n",
    "        diaSource.midpointMjdTai\n",
    "        diaSource.psfFlux\n",
    "        diaSource.psfFluxErr\n",
    "        diaSource.scienceFlux\n",
    "        diaSource.scienceFluxErr\n",
    "        diaSource.ra\n",
    "        diaSource.raErr\n",
    "        diaSource.visit\n",
    "        diaSource.x\n",
    "        diaSource.xErr\n",
    "        diaSource.y\n",
    "        diaSource.yErr\n",
    "        diaSource.scienceMag\n",
    "        diaSource.scienceMagErr\n",
    "        diaForcedSource\n",
    "        \"\"\".splitlines()\n",
    "    )\n",
    "    args = ImportArguments.reimport_from_hats(\n",
    "        input_path,\n",
    "        output_dir=TMP_DIR,\n",
    "        output_artifact_name=DATE_STR,\n",
    "        highest_healpix_order=11,\n",
    "        pixel_threshold=15_000,\n",
    "        skymap_alt_orders=[2, 4, 6],\n",
    "        row_group_kwargs={\"subtile_order_delta\": 1},\n",
    "        addl_hats_properties={\"hats_cols_default\": default_columns},\n",
    "        simple_progress_bar=True,\n",
    "        resume=False,\n",
    "    )\n",
    "    pipeline_with_client(args, client)\n",
    "\n",
    "\n",
    "def finalize_collection():\n",
    "    \"\"\"Generate new collection in the TEMP directory and move it to the COLLECTION_DIR.\"\"\"\n",
    "    new_collection_dir = TMP_DIR / \"dia_object_collection\"\n",
    "    # Create final collection folder.\n",
    "    !mkdir $new_collection_dir\n",
    "    # Move main catalog to final folder.\n",
    "    !mv $TMP_DIR/$DATE_STR $new_collection_dir\n",
    "    # Generate the collection.\n",
    "    generate_collection(catalog_path=new_collection_dir / DATE_STR, output_path=TMP_DIR)\n",
    "    # Move all contents of new colection to expected target output path.\n",
    "    !mv $new_collection_dir/* $COLLECTION_DIR\n",
    "    print(f\"Collection updated at {COLLECTION_DIR}\")\n",
    "\n",
    "\n",
    "def generate_collection(catalog_path, output_path):\n",
    "    \"\"\"Generate the collection for a given main catalog\"\"\"\n",
    "    args = (\n",
    "        CollectionArguments(\n",
    "            output_artifact_name=\"dia_object_collection\",\n",
    "            output_path=output_path,\n",
    "            simple_progress_bar=True,\n",
    "        )\n",
    "        .catalog(catalog_path=catalog_path, file_reader=\"parquet\")\n",
    "        .add_margin(margin_threshold=5.0, is_default=True)\n",
    "        .add_index(indexing_column=\"diaObjectId\")\n",
    "    )\n",
    "    pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729c76ff",
   "metadata": {},
   "source": [
    "### Main entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/s/stavar/.local/lib/python3.12/site-packages/lsdb/catalog/catalog.py:426: UserWarning: Right catalog has no margin, result will not include margin data.\n",
      "  warnings.warn(\n",
      "Planning  : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.01s/it]\n",
      "Mapping   : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [00:10<00:00,  3.35it/s]\n",
      "Binning   :   0%|                                                                                                                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n",
      "Reducing  : 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 120/120 [00:00<00:00, 349.93it/s]\n",
      "Finishing : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.62it/s]\n",
      "Finishing : 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 102.34it/s]\n",
      "Finishing : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 54.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection updated at /sdf/home/s/stavar/linccf/ppdb/dia_object_collection\n"
     ]
    }
   ],
   "source": [
    "if not COLLECTION_DIR.exists():\n",
    "    # Create a collection from scratch (first import)\n",
    "    os.makedirs(COLLECTION_DIR)\n",
    "    # Reimport catalog (to ensure partitioning is optimized and skymaps are up-to-date).\n",
    "    reimport(input_path=TMP_DIR / \"new_dia_object_lc\")\n",
    "    # Generate new collection and move it to COLLECTION_DIR.\n",
    "    finalize_collection()\n",
    "else:\n",
    "    # Concatenate existing collections ignoring duplicate object entries\n",
    "    # Load existing collection.\n",
    "    dia_object_collection = lsdb.open_catalog(COLLECTION_DIR, columns=\"all\")\n",
    "    # Load new DIA object data.\n",
    "    new_dia_object = lsdb.open_catalog(TMP_DIR / \"new_dia_object_lc\")\n",
    "    # Concatenate both catalogs.\n",
    "    concated = dia_object_collection.concat(new_dia_object)\n",
    "    # Save the concatenated catalog to disk.\n",
    "    concat_catalog_path = TMP_DIR / \"dia_object_concat\"\n",
    "    #concated.to_hats(concat_catalog_path, as_collection=False)\n",
    "    # Reimport catalog (to ensure partitioning is optimized and skymaps are up-to-date).\n",
    "    reimport(input_path=concat_catalog_path)\n",
    "    # Generate new collection and move it to COLLECTION_DIR.\n",
    "    finalize_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac330e7",
   "metadata": {},
   "source": [
    "Let's check that the updated collection has been updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7214fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-23\t\t2025-09-24_5arcs\t2025-09-25_diaObjectId\n",
      "2025-09-23_5arcs\t2025-09-24_diaObjectId\tcollection.properties\n",
      "2025-09-23_diaObjectId\t2025-09-25\n",
      "2025-09-24\t\t2025-09-25_5arcs\n"
     ]
    }
   ],
   "source": [
    "!ls $COLLECTION_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8638f1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#HATS Collection\n",
      "obs_collection=dia_object_collection\n",
      "hats_primary_table_url=2025-09-25\n",
      "all_margins=2025-09-25_5arcs\n",
      "default_margin=2025-09-25_5arcs\n",
      "all_indexes=diaObjectId 2025-09-25_diaObjectId\n",
      "hats_builder=hats-import v0.6.4, hats v0.6.5.dev4+ga69bbd9de\n",
      "hats_creation_date=2025-09-25T18:25UTC\n",
      "hats_estsize=1096180\n",
      "hats_release_date=2024-09-18\n",
      "hats_version=v0.1\n"
     ]
    }
   ],
   "source": [
    "!cat $COLLECTION_DIR/collection.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88e340",
   "metadata": {},
   "source": [
    "### Seeking feedback\n",
    "\n",
    "#### 1. How to handle incremental data for existing objects?\n",
    "\n",
    "- Do we augment the catalog by creating new rows for the object, or do we merge them into one?\n",
    "\n",
    "#### 2. Merging vs not to merge\n",
    "\n",
    "- \"Alerts\" for each given object might have different coordinates (ra/dec).\n",
    "\n",
    "    - If we do not merge information for the object, it might live in more than 1 partition.\n",
    "\n",
    "    - If the goal is to update as little pixel files as possible, and just \"append\", we might want not to merge.\n",
    "\n",
    "- If columns have information that collide, should we drop the existing ones and keep the latest?\n",
    "\n",
    "- If they do not collide, e.g. if an object alert has information for a filter for which we had no information before, do we just keep the new values for that filter?\n",
    "\n",
    "#### 3. How should we handle the nested light curves?\n",
    "\n",
    "- Pro for merging: we could update the lightcurves.\n",
    "\n",
    "- Sources should contain entirely new observations, so we would \"append\" them to their respective objects.\n",
    "\n",
    "- But aren't forced source somewhat \"iterative\"? Do we just keep the latest forced source, or do we need their full history?\n",
    "\n",
    "#### 4. Serving incremented catalogs\n",
    "\n",
    "The incremented catalogs have new parquet files and metadata. Since we're serving the catalogs live, overwriting the contents of a catalog is not stable.\n",
    "\n",
    "- Should we store the incremented version alongside the previous one, and replace after each cycle? Similar to the implementation of the cron jobs for TNS/VSX?\n",
    "\n",
    "- Should we explore Apache Iceberg, as a solution that supports transactions and data versioning? It does not currently support Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ddcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d61f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf $TMP_DIR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
