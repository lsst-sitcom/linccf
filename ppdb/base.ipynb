{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b474b22",
      "metadata": {},
      "source": [
        "## Import PPDB base catalog\n",
        "\n",
        "This notebook imports the base PPDB catalog (2025/26 fall and winter data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d453639c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import lsdb\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd674a39",
      "metadata": {},
      "source": [
        "Set up the Dask Client and the input/output dirs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "81c9c0b0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intermediate directory: /lscratch/stavar/tmp/tmpvpnt0q5h\n"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "from dask.distributed import Client\n",
        "from pathlib import Path\n",
        "\n",
        "# Path to the PPDB data 2025\n",
        "PPDB_DIR = Path(\"/sdf/scratch/rubin/ppdb/data/ppdb_lsstcam\")\n",
        "\n",
        "# Temporary directory\n",
        "tmp_dir = tempfile.TemporaryDirectory()\n",
        "print(f\"Intermediate directory: {tmp_dir.name}\")\n",
        "\n",
        "# Final target directory\n",
        "output_dir = Path(\"/sdf/data/rubin/shared/lsdb_commissioning/ppdb\")\n",
        "\n",
        "# Dask distributed client\n",
        "client = Client(n_workers=16, threads_per_worker=1, local_directory=tmp_dir.name, memory_limit=\"8GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33b7f2eb",
      "metadata": {},
      "source": [
        "### Get input files for each dataset type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d4530043",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 249 files for dia_object (2025/09/06 - 2026/01/20)\n",
            "Found 249 files for dia_source (2025/09/06 - 2026/01/20)\n",
            "Found 27 files for dia_forced_source (2026/01/08 - 2026/01/16)\n"
          ]
        }
      ],
      "source": [
        "def get_paths(dataset_type):\n",
        "    \"\"\"Return the parquet files for a given dataset type.\"\"\"\n",
        "    dataset_name = \"\".join(word.capitalize() for word in dataset_type.split(\"_\"))\n",
        "    files = sorted(PPDB_DIR.rglob(f\"{dataset_name}.parquet\"))\n",
        "    get_date = lambda p: \"/\".join(p.relative_to(PPDB_DIR).parts[:3])\n",
        "    print(f\"Found {len(files)} files for {dataset_type} ({get_date(files[0])} - {get_date(files[-1])})\")\n",
        "    return files\n",
        "\n",
        "object_files = get_paths(\"dia_object\")\n",
        "source_files = get_paths(\"dia_source\")\n",
        "forced_source_files = get_paths(\"dia_forced_source\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f893ea",
      "metadata": {},
      "source": [
        "### Import base catalogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ecd81bb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "from hats_import import pipeline_with_client\n",
        "from hats_import.catalog.arguments import ImportArguments\n",
        "from hats_import.catalog.file_readers import ParquetPyarrowReader\n",
        "from hats_import.margin_cache.margin_cache_arguments import MarginCacheArguments\n",
        "from lsst.resources import ResourcePath\n",
        "\n",
        "\n",
        "def import_dataset(dataset_type, input_file_list, catalog_type):\n",
        "    \"\"\"Import `dataset_type` with files of up to 1GiB\"\"\"\n",
        "    schema_filepath = _download_schema(dataset_type, input_file_list[0])\n",
        "    args = ImportArguments(\n",
        "        output_path=output_dir,\n",
        "        output_artifact_name=dataset_type,\n",
        "        input_file_list=input_file_list,\n",
        "        file_reader=ParquetPyarrowReader(),\n",
        "        ra_column=\"ra\",\n",
        "        dec_column=\"dec\",\n",
        "        catalog_type=catalog_type,\n",
        "        byte_pixel_threshold=1<<30, # 1 GiB\n",
        "        use_schema_file=schema_filepath,\n",
        "        simple_progress_bar=True,\n",
        "        resume=False,\n",
        "    )\n",
        "    pipeline_with_client(args, client)\n",
        "\n",
        "def _download_schema(dataset_type, single_parquet_path):\n",
        "    \"\"\"Downloads the schema for `dataset_type`\"\"\"\n",
        "    with ResourcePath(single_parquet_path).open(\"rb\") as file:\n",
        "        schema = pq.read_schema(file).remove_metadata()\n",
        "    schema_table = pa.table({field.name: pa.array([], type=field.type) for field in schema})\n",
        "    schema_filepath = f\"{tmp_dir.name}/{dataset_type}_schema.parquet\"\n",
        "    pq.write_table(schema_table, schema_filepath)\n",
        "    return schema_filepath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4c7a512c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Catalog: Planning  : 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 246.00it/s]\n",
            "Catalog: Mapping   : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 249/249 [00:17<00:00, 14.17it/s]\n",
            "Catalog: Binning   : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:52<00:00, 26.19s/it]\n",
            "Catalog: Splitting : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 249/249 [00:03<00:00, 77.10it/s]\n",
            "Catalog: Reducing  : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.06it/s]\n",
            "Catalog: Finishing : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.61it/s]\n",
            "Catalog: Planning  : 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 156.42it/s]\n",
            "Catalog: Mapping   : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 249/249 [00:15<00:00, 16.55it/s]\n",
            "Catalog: Binning   : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:52<00:00, 26.24s/it]\n",
            "Catalog: Splitting : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 249/249 [00:03<00:00, 72.34it/s]\n",
            "Catalog: Reducing  : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.78it/s]\n",
            "Catalog: Finishing : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.07it/s]\n",
            "Catalog: Planning  : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 82.35it/s]\n",
            "Catalog: Mapping   : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:02<00:00, 11.13it/s]\n",
            "Catalog: Binning   : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:49<00:00, 24.84s/it]\n",
            "Catalog: Splitting : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 53.34it/s]\n",
            "Catalog: Reducing  : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.85it/s]\n",
            "Catalog: Finishing : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  9.23it/s]\n"
          ]
        }
      ],
      "source": [
        "import_dataset(\"dia_object\", object_files, catalog_type=\"object\")\n",
        "import_dataset(\"dia_source\", source_files, catalog_type=\"source\")\n",
        "import_dataset(\"dia_forced_source\", forced_source_files, catalog_type=\"source\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3385a154",
      "metadata": {},
      "source": [
        "### Post-processing\n",
        "\n",
        "About 8% of objects have duplicates (same `diaObjectId`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "af8a9114",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(7.705989774842453)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dia_object = lsdb.open_catalog(output_dir / \"dia_object\")\n",
        "_, counts = np.unique(dia_object[\"diaObjectId\"], return_counts=True)\n",
        "n_dup_ids = np.sum(counts > 1)\n",
        "n_dup_ids/len(dia_object)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94be3b35",
      "metadata": {},
      "source": [
        "We will keep the oned of latest `validityStartMjdTai`, and add mag/magerr columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f7404e01",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "dia_object:   0%|                                                                                                                                                                                                                                                                           | 0/4 [00:00<?, ?it/s]/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "dia_object:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3/4 [00:00<00:00,  4.45it/s]/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "dia_object: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.79it/s]\n",
            "dia_source:   0%|                                                                                                                                                                                                                                                                           | 0/6 [00:00<?, ?it/s]/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "dia_source:  17%|███████████████████████████████████████████▏                                                                                                                                                                                                                       | 1/6 [00:00<00:00,  9.56it/s]/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "dia_source: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.50it/s]\n",
            "dia_forced_source:   0%|                                                                                                                                                                                                                                                                    | 0/2 [00:00<?, ?it/s]/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "/sdf/group/rubin/sw/conda/envs/lsst-scipipe-12.1.0/lib/python3.13/site-packages/pandas/core/arraylike.py:492: RuntimeWarning: invalid value encountered in log10\n",
            "  return getattr(ufunc, method)(*new_inputs, **kwargs)\n",
            "dia_forced_source: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  5.37it/s]\n"
          ]
        }
      ],
      "source": [
        "from postprocess import postprocess_catalog\n",
        "\n",
        "flux_col_prefixes = [f\"{band}_scienceFluxMean\" for band in list(\"ugrizy\")]\n",
        "postprocess_catalog(client, output_dir, \"dia_object\", flux_col_prefixes, \"validityStartMjdTai\")\n",
        "postprocess_catalog(client, output_dir, \"dia_source\", [\"scienceFlux\"])\n",
        "postprocess_catalog(client, output_dir, \"dia_forced_source\", [\"scienceFlux\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcc408f9",
      "metadata": {},
      "source": [
        "### Nest sources in objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fcf8e57a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_sources_with_margin(dataset_type, margin_arcsec=5):\n",
        "    \"\"\"Create source margins for nesting\"\"\"\n",
        "    input_catalog_path = output_dir / dataset_type\n",
        "    margin_name = f\"{dataset_type}_{margin_arcsec}arcs\"\n",
        "    args = MarginCacheArguments(\n",
        "        input_catalog_path=input_catalog_path,\n",
        "        output_path=tmp_dir.name,\n",
        "        margin_threshold=margin_arcsec,\n",
        "        output_artifact_name=margin_name,\n",
        "        progress_bar=False,\n",
        "        resume=False,\n",
        "    )\n",
        "    pipeline_with_client(args, client)\n",
        "    margin_path = f\"{tmp_dir.name}/{margin_name}\"\n",
        "    return lsdb.open_catalog(input_catalog_path, margin_cache=margin_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fbfafbad",
      "metadata": {},
      "outputs": [],
      "source": [
        "dia_object = lsdb.open_catalog(output_dir / \"dia_object\")\n",
        "dia_source = load_sources_with_margin(\"dia_source\")\n",
        "dia_forced_source = load_sources_with_margin(\"dia_forced_source\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc1aadb",
      "metadata": {},
      "source": [
        "There are ~6% of sources with no `diaObjectId`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "972cddaa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(5.6193954448733034)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_sources_no_objid = np.sum(dia_source[\"diaObjectId\"].isna().compute())\n",
        "n_sources_no_objid/len(dia_source)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f3eb2a",
      "metadata": {},
      "source": [
        "We'll need to filter them out otherwise we cannot nest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "83de027d",
      "metadata": {},
      "outputs": [],
      "source": [
        "valid_dia_source = dia_source[~dia_source[\"diaObjectId\"].isna()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65cac5d2",
      "metadata": {},
      "source": [
        "That does not seem to be an issue for `diaForcedSource`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3939e846",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(dia_forced_source[\"diaObjectId\"].isna().compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7304fe58",
      "metadata": {},
      "source": [
        "Nest sources and forced sources and write to disk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef546e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/sdf/home/s/stavar/.local/lib/python3.13/site-packages/lsdb/dask/join_catalog_data.py:474: RuntimeWarning: Right catalog does not have a margin cache. Results may be incomplete and/or inaccurate.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from nest import nest_sources\n",
        "\n",
        "dia_object_lc = nest_sources(dia_object, valid_dia_source, dia_forced_source)\n",
        "dia_collection_dir = output_dir / \"dia_object_collection\"\n",
        "dia_object_lc.to_hats(dia_collection_dir, catalog_name=\"dia_object_lc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bc82cf8",
      "metadata": {},
      "source": [
        "### Finish collection\n",
        "\n",
        "Generate margin and index catalogs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3853fb8e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Margin: Planning  : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.61it/s]\n",
            "Margin: Mapping   : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  7.04it/s]\n",
            "Margin: Binning   : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 85.98it/s]\n",
            "Margin: Reducing  : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 365.61it/s]\n",
            "Margin: Finishing : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 26.72it/s]\n",
            "Index: Finishing : 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 15.11it/s]\n",
            "Collection: Finishing : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 27.43it/s]\n"
          ]
        }
      ],
      "source": [
        "from hats_import.collection.arguments import CollectionArguments\n",
        "\n",
        "args = (\n",
        "    CollectionArguments(\n",
        "        output_artifact_name=\"dia_object_collection\",\n",
        "        new_catalog_name=\"dia_object_lc\",\n",
        "        output_path=output_dir,\n",
        "        simple_progress_bar=True,\n",
        "    )\n",
        "    .catalog(\n",
        "        catalog_path=output_dir / \"dia_object_collection\" / \"dia_object_lc\",\n",
        "    )\n",
        "    .add_margin(margin_threshold=5.0, is_default=True)\n",
        "    .add_index(indexing_column=\"diaObjectId\")\n",
        ")\n",
        "pipeline_with_client(args, client)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de689220",
      "metadata": {},
      "source": [
        "Let's store which files we ingested for later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a46d278e",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_paths_dir = (dia_collection_dir / \"input_paths\")\n",
        "input_paths_dir.mkdir(exist_ok=True)\n",
        "\n",
        "def save_paths(dataset_type, filepaths):\n",
        "    with (input_paths_dir / f\"{dataset_type}.txt\").open(\"a\") as f:\n",
        "        f.writelines(str(p) + \"\\n\" for p in filepaths)\n",
        "\n",
        "save_paths(\"dia_object\", object_files)\n",
        "save_paths(\"dia_source\", source_files)\n",
        "save_paths(\"dia_forced_source\", forced_source_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec7f30d",
      "metadata": {},
      "source": [
        "### Some validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0f32a9d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = lsdb.open_catalog(output_dir / \"dia_object_collection\").compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dfc0a96",
      "metadata": {},
      "source": [
        "#### Checking objects\n",
        "\n",
        "We have the same set of objects in the collection as in the original data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8d94aeaf",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "input_objs = pd.read_parquet(object_files, dtype_backend=\"pyarrow\")\n",
        "input_obj_ids = np.unique(input_objs[\"diaObjectId\"])\n",
        "assert set(df[\"diaObjectId\"]) == set(input_obj_ids)\n",
        "assert len(input_obj_ids) == len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39235b76",
      "metadata": {},
      "source": [
        "#### Checking sources\n",
        "\n",
        "All objects have sources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1db4d360",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df[~df[\"diaSource\"].isna()])/len(df)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3135c35",
      "metadata": {},
      "source": [
        "There are as many sources in the collection as in the base catalog (minus those with no diaObjectId):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "906c3407",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_sources = pd.read_parquet(source_files, dtype_backend=\"pyarrow\")\n",
        "expected_sources = input_sources[~input_sources[\"diaObjectId\"].isna()]\n",
        "assert len(expected_sources) == len(df[\"diaSource\"].explode())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "891fcf39",
      "metadata": {},
      "source": [
        "Though there are ~7% of objects for which \"nDiaSource\" doesn't match the number of \"diaSource\" we got:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8451e4e9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.255606249555245"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nested_pandas.utils import count_nested\n",
        "count_df = count_nested(df, \"diaSource\", join=True)\n",
        "unmatched = count_df[count_df[\"nDiaSources\"] != count_df[\"n_diaSource\"]]\n",
        "len(unmatched)/len(count_df)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "978d20d2",
      "metadata": {},
      "source": [
        "#### Checking forced sources\n",
        "\n",
        "Only ~5% of objects have forced sources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "3308d216",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.169310311439514"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df[~df[\"diaForcedSource\"].isna()])/len(df)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ba8381c",
      "metadata": {},
      "source": [
        "This seems to make sense according to the input data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d7772dd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "forced_sources = pd.read_parquet(forced_source_files, dtype_backend=\"pyarrow\")\n",
        "expected_f_sources = forced_sources[~forced_sources[\"diaObjectId\"].isna()]\n",
        "assert len(expected_f_sources) == len(df[\"diaForcedSource\"].explode())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
