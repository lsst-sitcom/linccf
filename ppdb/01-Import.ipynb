{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be00b793",
   "metadata": {},
   "source": [
    "## Import PPDB base catalogs\n",
    "\n",
    "Hatsify DIA object, source and forced source data from PPDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30815f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import tempfile\n",
    "\n",
    "from dask.distributed import Client\n",
    "from hats_import import pipeline_with_client\n",
    "from hats_import.collection.arguments import ImportArguments\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf2181",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdb_dir = Path(\"/sdf/scratch/rubin/ppdb/data/lsstcam\")\n",
    "hats_dir = Path(\"/sdf/data/rubin/shared/lsdb_commissioning/hats/PPDB_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = tempfile.TemporaryDirectory()\n",
    "tmp_dir = Path(tmp_path.name)\n",
    "client = Client(n_workers=16, threads_per_worker=1, local_directory=tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae194ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(dataset_type):\n",
    "    \"\"\"Return all parquet files for a given dataset type.\"\"\"\n",
    "    dataset_name = ''.join(word.capitalize() for word in dataset_type.split('_'))\n",
    "    files = sorted(ppdb_dir.rglob(f\"{dataset_name}.parquet\"))\n",
    "    print(f\"Found {len(files)} {dataset_type} parquet files\")\n",
    "    return files\n",
    "\n",
    "def download_schema(dataset_type, parquet_filepath):\n",
    "    \"\"\"Obtain the final schema for a dataset type.\"\"\"\n",
    "    with open(parquet_filepath, \"rb\") as file:\n",
    "        schema = pq.read_schema(file).remove_metadata()\n",
    "    schema_table = pa.table(\n",
    "        {field.name: pa.array([], type=field.type) for field in schema}\n",
    "    )\n",
    "    schema_filepath = tmp_dir / f\"{dataset_type}_schema.parquet\"\n",
    "    pq.write_table(schema_table, schema_filepath)\n",
    "    print(f\"Wrote {dataset_type} schema to {schema_filepath}\")\n",
    "    return schema_filepath\n",
    "\n",
    "def get_paths_and_schema(dataset_type):\n",
    "    paths = get_paths(dataset_type)\n",
    "    # Use the first parquet schema as the final schema\n",
    "    schema_path = download_schema(dataset_type, paths[0])\n",
    "    return paths, schema_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26903c6a",
   "metadata": {},
   "source": [
    "### dia_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, schema_path = get_paths_and_schema(\"dia_object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202693d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    output_path=hats_dir,\n",
    "    output_artifact_name=\"dia_object\",\n",
    "    input_file_list=paths,\n",
    "    file_reader=\"parquet\",\n",
    "    ra_column=\"ra\",\n",
    "    dec_column=\"dec\",\n",
    "    catalog_type=\"object\",\n",
    "    pixel_threshold=5_000_000,\n",
    "    use_schema_file=schema_path,\n",
    "    simple_progress_bar=True,\n",
    "    resume=False,\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eaa595",
   "metadata": {},
   "source": [
    "### dia_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, schema_path = get_paths_and_schema(\"dia_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    output_path=hats_dir,\n",
    "    output_artifact_name=\"dia_source\",\n",
    "    input_file_list=paths,\n",
    "    file_reader=\"parquet\",\n",
    "    ra_column=\"ra\",\n",
    "    dec_column=\"dec\",\n",
    "    catalog_type=\"source\",\n",
    "    pixel_threshold=4_000_000,\n",
    "    use_schema_file=schema_path,\n",
    "    simple_progress_bar=True,\n",
    "    resume=False,\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ff896",
   "metadata": {},
   "source": [
    "### dia_forced_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, schema_path = get_paths_and_schema(\"dia_forced_source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    output_path=hats_dir,\n",
    "    output_artifact_name=\"dia_forced_source\",\n",
    "    input_file_list=paths,\n",
    "    file_reader=\"parquet\",\n",
    "    ra_column=\"ra\",\n",
    "    dec_column=\"dec\",\n",
    "    catalog_type=\"source\",\n",
    "    pixel_threshold=25_000_000,\n",
    "    use_schema_file=schema_path,\n",
    "    simple_progress_bar=True,\n",
    "    resume=False,    \n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9093b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
