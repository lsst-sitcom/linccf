{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5a49bb-9251-4b4a-b347-fbef01b945eb",
   "metadata": {},
   "source": [
    "# Import to HATS\n",
    "\n",
    "Use hats-import to ingest the parquet URLs and create each HATS catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab38dd4-ec6d-4d45-9b0d-f41652e9779b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T00:58:02.236554Z",
     "iopub.status.busy": "2025-02-12T00:58:02.235997Z",
     "iopub.status.idle": "2025-02-12T00:58:04.404971Z",
     "shell.execute_reply": "2025-02-12T00:58:04.404469Z",
     "shell.execute_reply.started": "2025-02-12T00:58:02.236528Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from dask.distributed import Client\n",
    "from dimension_reader import DimensionParquetReader\n",
    "from hats_import import pipeline_with_client\n",
    "from hats_import.catalog.arguments import ImportArguments\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a6b07-f916-4e26-8862-ed50f2e669d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T00:58:05.467248Z",
     "iopub.status.busy": "2025-02-12T00:58:05.466340Z",
     "iopub.status.idle": "2025-02-12T00:58:05.470049Z",
     "shell.execute_reply": "2025-02-12T00:58:05.469655Z",
     "shell.execute_reply.started": "2025-02-12T00:58:05.467230Z"
    }
   },
   "outputs": [],
   "source": [
    "INSTRUMENT = os.environ[\"INSTRUMENT\"]\n",
    "RUN = os.environ[\"RUN\"]\n",
    "VERSION = os.environ[\"VERSION\"]\n",
    "COLLECTION = os.environ[\"COLLECTION\"]\n",
    "OUTPUT_DIR = Path(os.environ[\"OUTPUT_DIR\"])\n",
    "\n",
    "print(f\"INSTRUMENT: {INSTRUMENT}\")\n",
    "print(f\"RUN: {RUN}\")\n",
    "print(f\"VERSION: {VERSION}\")\n",
    "print(f\"COLLECTION: {COLLECTION}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "\n",
    "collections = f\"{INSTRUMENT}/runs/DRP/{RUN}/{VERSION}/{COLLECTION}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c1c4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T00:58:06.473260Z",
     "iopub.status.busy": "2025-02-12T00:58:06.472686Z",
     "iopub.status.idle": "2025-02-12T00:58:06.481610Z",
     "shell.execute_reply": "2025-02-12T00:58:06.481233Z",
     "shell.execute_reply.started": "2025-02-12T00:58:06.473242Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_dir = OUTPUT_DIR / \"raw\" / VERSION\n",
    "hats_dir = OUTPUT_DIR / \"hats\" / VERSION\n",
    "hats_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860e7b9-0230-41da-9d5f-aebcb925bb61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T00:58:08.332448Z",
     "iopub.status.busy": "2025-02-12T00:58:08.331892Z",
     "iopub.status.idle": "2025-02-12T00:58:09.704368Z",
     "shell.execute_reply": "2025-02-12T00:58:09.703833Z",
     "shell.execute_reply.started": "2025-02-12T00:58:08.332432Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_path = tempfile.TemporaryDirectory()\n",
    "tmp_dir = tmp_path.name\n",
    "client = Client(n_workers=16, threads_per_worker=1, local_directory=tmp_dir, memory_limit=\"8GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11c220",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a6cf2-991d-4dca-b5e0-5155a960712a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T00:58:13.416041Z",
     "iopub.status.busy": "2025-02-12T00:58:13.415732Z",
     "iopub.status.idle": "2025-02-12T00:58:13.419029Z",
     "shell.execute_reply": "2025-02-12T00:58:13.418480Z",
     "shell.execute_reply.started": "2025-02-12T00:58:13.416025Z"
    }
   },
   "outputs": [],
   "source": [
    "from lsst.resources import ResourcePath\n",
    "\n",
    "def get_paths(dataset_type):\n",
    "    index_dir = raw_dir / \"index\" / dataset_type\n",
    "    return list(index_dir.glob(\"*.csv\"))\n",
    "\n",
    "\n",
    "def download_dataset_schema(\n",
    "    dataset_type, columns_to_select=None, dimension_columns=None\n",
    "):\n",
    "    with open(raw_dir / \"paths\" / f\"{dataset_type}.txt\", \"r\") as file:\n",
    "        single_parquet_path = file.readline().strip()\n",
    "    with ResourcePath(single_parquet_path).open(\"rb\") as file:\n",
    "        schema = pq.read_schema(file).remove_metadata()\n",
    "    schema_table = pa.table(\n",
    "        {field.name: pa.array([], type=field.type) for field in schema}\n",
    "    )\n",
    "    schema_table = _select_desired_columns(schema_table, columns_to_select)\n",
    "    schema_table = _add_dimensions_to_schema(schema_table, dimension_columns)\n",
    "    pq.write_table(schema_table, raw_dir / f\"{dataset_type}_schema.parquet\")\n",
    "\n",
    "\n",
    "def _select_desired_columns(schema_table, columns_to_select=None):\n",
    "    # Select subset of columns keeping the order from the original schema.\n",
    "    if columns_to_select is not None:\n",
    "        ordered_columns = [\n",
    "            col for col in schema_table.column_names if col in columns_to_select\n",
    "        ]\n",
    "        schema_table = schema_table.select(ordered_columns)\n",
    "    return schema_table\n",
    "\n",
    "\n",
    "def _add_dimensions_to_schema(schema_table, dimension_columns=None):\n",
    "    # Add dimension columns to the schema (e.g. tract and/or patch).\n",
    "    if dimension_columns is not None:\n",
    "        for dimension_column in dimension_columns:\n",
    "            if dimension_column not in schema_table.column_names:\n",
    "                schema_table = schema_table.append_column(\n",
    "                    dimension_column, pa.array([], type=pa.int64())\n",
    "                )\n",
    "    return schema_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ae0f42",
   "metadata": {},
   "source": [
    "#### dia_object\n",
    "\n",
    "We realized that the dia object table columns in the input files might come in different orders. To make sure we get a consistent arrow schema, we can grab the schema for a single parquet file and use it throughout the import pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_obj_files = get_paths(\"dia_object\")\n",
    "dia_obj_default_columns = [\"diaObjectId\", \"ra\", \"dec\", \"nDiaSources\"]\n",
    "dia_obj_dimension_columns = set(pd.read_csv(dia_obj_files[0]).columns) - set([\"path\"])\n",
    "\n",
    "# To import all columns set dia_obj_default_columns to None.\n",
    "download_dataset_schema(\n",
    "    \"dia_object\", dia_obj_default_columns, dia_obj_dimension_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c9060-d650-4f51-b43a-264aee21c3a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T00:58:14.473497Z",
     "iopub.status.busy": "2025-02-12T00:58:14.473215Z",
     "iopub.status.idle": "2025-02-12T00:58:33.229625Z",
     "shell.execute_reply": "2025-02-12T00:58:33.229206Z",
     "shell.execute_reply.started": "2025-02-12T00:58:14.473481Z"
    }
   },
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    output_path=hats_dir,\n",
    "    output_artifact_name=\"dia_object\",\n",
    "    input_file_list=dia_obj_files,\n",
    "    # To import all columns remove `column_names` argument.\n",
    "    file_reader=DimensionParquetReader(column_names=dia_obj_default_columns),\n",
    "    ra_column=\"ra\",\n",
    "    dec_column=\"dec\",\n",
    "    catalog_type=\"object\",\n",
    "    pixel_threshold=5_000_000,\n",
    "    simple_progress_bar=True,\n",
    "    resume=False,\n",
    "    # Use the final schema previously constructed.\n",
    "    use_schema_file=raw_dir / \"dia_object_schema.parquet\",\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb1d3f",
   "metadata": {},
   "source": [
    "#### dia_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d909565-2e74-4f7c-9ca4-6dd7f7abd6ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T00:58:37.007710Z",
     "iopub.status.busy": "2025-02-12T00:58:37.007407Z",
     "iopub.status.idle": "2025-02-12T00:59:05.404109Z",
     "shell.execute_reply": "2025-02-12T00:59:05.403701Z",
     "shell.execute_reply.started": "2025-02-12T00:58:37.007694Z"
    }
   },
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    output_path=hats_dir,\n",
    "    output_artifact_name=\"dia_source\",\n",
    "    input_file_list=get_paths(\"dia_source\"),\n",
    "    file_reader=DimensionParquetReader(),\n",
    "    ra_column=\"ra\",\n",
    "    dec_column=\"dec\",\n",
    "    catalog_type=\"source\",\n",
    "    pixel_threshold=4_000_000,\n",
    "    simple_progress_bar=True,\n",
    "    resume=False,\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088c7aa",
   "metadata": {},
   "source": [
    "#### dia_object_forced_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1a876-2466-4c8c-9b06-f24ea4e4eae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T00:59:10.152471Z",
     "iopub.status.busy": "2025-02-12T00:59:10.152006Z",
     "iopub.status.idle": "2025-02-12T01:07:38.099809Z",
     "shell.execute_reply": "2025-02-12T01:07:38.099343Z",
     "shell.execute_reply.started": "2025-02-12T00:59:10.152450Z"
    }
   },
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    output_path=hats_dir,\n",
    "    output_artifact_name=\"dia_object_forced_source\",\n",
    "    input_file_list=get_paths(\"dia_object_forced_source\"),\n",
    "    file_reader=DimensionParquetReader(),\n",
    "    ra_column=\"coord_ra\",\n",
    "    dec_column=\"coord_dec\",\n",
    "    catalog_type=\"source\",\n",
    "    pixel_threshold=25_000_000,\n",
    "    simple_progress_bar=True,\n",
    "    resume=False,\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ba98d",
   "metadata": {},
   "source": [
    "#### object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46895e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T01:09:07.757295Z",
     "iopub.status.busy": "2025-02-12T01:09:07.756828Z",
     "iopub.status.idle": "2025-02-12T01:09:07.762960Z",
     "shell.execute_reply": "2025-02-12T01:09:07.762501Z",
     "shell.execute_reply.started": "2025-02-12T01:09:07.757280Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_per_band = []\n",
    "for band in list(\"ugrizy\"):\n",
    "    for flux_type in [\"psf\", \"kron\"]:\n",
    "        prefix = f\"{band}_{flux_type}\"\n",
    "        cols_per_band.extend([f\"{prefix}Flux\", f\"{prefix}FluxErr\"])\n",
    "    cols_per_band.append(f\"{band}_kronRad\")\n",
    "\n",
    "obj_default_columns = [\n",
    "    \"objectId\",\n",
    "    \"refBand\",\n",
    "    \"shape_flag\",\n",
    "    \"sky_object\",\n",
    "    \"parentObjectId\",\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    \"xErr\",\n",
    "    \"yErr\",\n",
    "    \"shape_yy\",\n",
    "    \"shape_xx\",\n",
    "    \"shape_xy\",\n",
    "    \"coord_ra\",\n",
    "    \"coord_dec\",\n",
    "    \"coord_raErr\",\n",
    "    \"coord_decErr\",\n",
    "    \"tract\",\n",
    "    \"patch\",\n",
    "    \"detect_isIsolated\",\n",
    "] + cols_per_band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b95da",
   "metadata": {},
   "source": [
    "Similarly to what we did previously, obtain the schema for the object dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3da2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_files = get_paths(\"object\")\n",
    "obj_dimension_columns = set(pd.read_csv(obj_files[0]).columns) - set([\"path\"])\n",
    "\n",
    "# To import all columns set obj_default_columns to None.\n",
    "download_dataset_schema(\"object\", obj_default_columns, obj_dimension_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4292007-30bd-4822-991c-300e0a3ff017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T01:09:09.029946Z",
     "iopub.status.busy": "2025-02-12T01:09:09.029732Z",
     "iopub.status.idle": "2025-02-12T01:09:44.600757Z",
     "shell.execute_reply": "2025-02-12T01:09:44.599804Z",
     "shell.execute_reply.started": "2025-02-12T01:09:09.029931Z"
    }
   },
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    output_path=hats_dir,\n",
    "    output_artifact_name=\"object\",\n",
    "    input_file_list=obj_files,\n",
    "    # To import all columns remove `column_names` argument.\n",
    "    file_reader=DimensionParquetReader(\n",
    "        column_names=obj_default_columns, chunksize=250_000\n",
    "    ),\n",
    "    ra_column=\"coord_ra\",\n",
    "    dec_column=\"coord_dec\",\n",
    "    catalog_type=\"object\",\n",
    "    pixel_threshold=300_000,\n",
    "    simple_progress_bar=True,\n",
    "    resume=False,\n",
    "    # Use the final schema previously constructed.\n",
    "    use_schema_file=raw_dir / \"object_schema.parquet\",\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302bb848",
   "metadata": {},
   "source": [
    "#### source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3ef3e-e426-4282-92e8-897bd11c87e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T01:09:47.656340Z",
     "iopub.status.busy": "2025-02-12T01:09:47.655783Z",
     "iopub.status.idle": "2025-02-12T01:16:27.288621Z",
     "shell.execute_reply": "2025-02-12T01:16:27.287858Z",
     "shell.execute_reply.started": "2025-02-12T01:09:47.656324Z"
    }
   },
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    output_path=hats_dir,\n",
    "    output_artifact_name=\"source2\",\n",
    "    input_file_list=get_paths(\"source2\"),\n",
    "    file_reader=DimensionParquetReader(),\n",
    "    ra_column=\"ra\",\n",
    "    dec_column=\"dec\",\n",
    "    catalog_type=\"source\",\n",
    "    pixel_threshold=1_000_000,\n",
    "    simple_progress_bar=True,\n",
    "    resume=False,\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e867bf",
   "metadata": {},
   "source": [
    "#### object_forced_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7519309d-509c-4074-965f-aef6e239ac5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:29:01.831212Z",
     "iopub.status.busy": "2025-01-30T14:29:01.830919Z",
     "iopub.status.idle": "2025-01-30T14:37:46.203302Z",
     "shell.execute_reply": "2025-01-30T14:37:46.202939Z",
     "shell.execute_reply.started": "2025-01-30T14:29:01.831192Z"
    }
   },
   "outputs": [],
   "source": [
    "args = ImportArguments(\n",
    "    output_path=hats_dir,\n",
    "    output_artifact_name=\"object_forced_source\",\n",
    "    input_file_list=get_paths(\"object_forced_source\"),\n",
    "    file_reader=DimensionParquetReader(),\n",
    "    ra_column=\"coord_ra\",\n",
    "    dec_column=\"coord_dec\",\n",
    "    catalog_type=\"source\",\n",
    "    pixel_threshold=25_000_000,\n",
    "    simple_progress_bar=True,\n",
    "    resume=False,\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb66ea74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T00:55:16.471447Z",
     "iopub.status.busy": "2025-02-12T00:55:16.471189Z",
     "iopub.status.idle": "2025-02-12T00:55:18.012222Z",
     "shell.execute_reply": "2025-02-12T00:55:18.011671Z",
     "shell.execute_reply.started": "2025-02-12T00:55:16.471431Z"
    }
   },
   "outputs": [],
   "source": [
    "client.close()\n",
    "tmp_path.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
