{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7248adc-f819-4435-a094-0c0e5f2802d1",
   "metadata": {},
   "source": [
    "# Create Index Files\n",
    "\n",
    "Author: Melissa\n",
    "\n",
    "This script has a few useful bits:\n",
    "\n",
    "- Create batches of files to import\n",
    "   - These will ideally be close to each other (e.g. by tract)\n",
    "   - These will also contain points from the reference id (which are not included in the parquet files)\n",
    "- Get the original file sizes and many other fun data points for further debugging\n",
    "- Estimate the pixel thresholds for the various table types.\n",
    "   - NB: this analysis was run at the beginning of comcam testing, and we've used those values in the subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c140e6e1-418a-420d-acce-451b4a9628da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:43:03.439565Z",
     "iopub.status.busy": "2025-02-11T15:43:03.439254Z",
     "iopub.status.idle": "2025-02-11T15:43:03.442411Z",
     "shell.execute_reply": "2025-02-11T15:43:03.442036Z",
     "shell.execute_reply.started": "2025-02-11T15:43:03.439551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generic python packages\n",
    "import os\n",
    "\n",
    "# LSST Science Pipelines (Stack) packages\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b470d081-69f0-4cd5-9c68-6554c9325bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:43:04.009118Z",
     "iopub.status.busy": "2025-02-11T15:43:04.008829Z",
     "iopub.status.idle": "2025-02-11T15:43:04.027027Z",
     "shell.execute_reply": "2025-02-11T15:43:04.026730Z",
     "shell.execute_reply.started": "2025-02-11T15:43:04.009105Z"
    }
   },
   "outputs": [],
   "source": [
    "DRP_VERSION = os.environ[\"DRP_VERSION\"]\n",
    "print(f\"DRP_VERSION: {DRP_VERSION}\")\n",
    "raw_dir = Path(f\"/sdf/data/rubin/shared/lsdb_commissioning/raw/{DRP_VERSION}\")\n",
    "index_dir = raw_dir / \"index\"\n",
    "index_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6042aceb-4055-4934-b563-948209f94cc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:43:04.622812Z",
     "iopub.status.busy": "2025-02-11T15:43:04.622523Z",
     "iopub.status.idle": "2025-02-11T15:43:04.627079Z",
     "shell.execute_reply": "2025-02-11T15:43:04.626766Z",
     "shell.execute_reply.started": "2025-02-11T15:43:04.622797Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_sizes(dataset_type):\n",
    "    file_pointer = raw_dir / \"paths\" / f\"{dataset_type}.txt\"\n",
    "\n",
    "    with file_pointer.open(\"r\", encoding=\"utf8\") as _text_file:\n",
    "        paths = _text_file.readlines()\n",
    "    paths = [path.strip() for path in paths]\n",
    "\n",
    "    print(f\"Found {len(paths)} files for {dataset_type}\")\n",
    "\n",
    "    ref_frame = pd.read_csv(raw_dir / \"refs\" / f\"{dataset_type}.csv\")\n",
    "    ref_frame[\"path\"] = paths\n",
    "\n",
    "    num_columns = []\n",
    "    num_rows = []\n",
    "    num_row_groups = []\n",
    "    file_size = []\n",
    "\n",
    "    for path in tqdm(paths):\n",
    "        parquet_md = pq.ParquetFile(path.strip()).metadata\n",
    "        num_columns.append(parquet_md.num_columns)\n",
    "        num_rows.append(parquet_md.num_rows)\n",
    "        num_row_groups.append(parquet_md.num_row_groups)\n",
    "        file_size.append(os.path.getsize(path))\n",
    "\n",
    "    ref_frame[\"num_columns\"] = num_columns\n",
    "    ref_frame[\"num_rows\"] = num_rows\n",
    "    ref_frame[\"num_row_groups\"] = num_row_groups\n",
    "    ref_frame[\"file_size\"] = file_size\n",
    "    ref_frame[\"gbs\"] = ref_frame[\"file_size\"] / (1024 * 1024 * 1024)\n",
    "\n",
    "    ref_frame.to_csv(raw_dir / \"sizes\" / f\"{dataset_type}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140819ad-e36d-4c78-8d10-f894eb1af545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:43:06.129478Z",
     "iopub.status.busy": "2025-02-11T15:43:06.129145Z",
     "iopub.status.idle": "2025-02-11T15:43:06.132021Z",
     "shell.execute_reply": "2025-02-11T15:43:06.131673Z",
     "shell.execute_reply.started": "2025-02-11T15:43:06.129455Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_types = [\n",
    "    \"dia_object\",\n",
    "    \"dia_source\",\n",
    "    \"dia_object_forced_source\",\n",
    "    \"object\",\n",
    "    \"source\",\n",
    "    \"object_forced_source\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec92ee27-ea54-40cf-bb2e-8d80596d8f22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:43:08.519495Z",
     "iopub.status.busy": "2025-02-11T15:43:08.519129Z",
     "iopub.status.idle": "2025-02-11T15:43:40.414975Z",
     "shell.execute_reply": "2025-02-11T15:43:40.414492Z",
     "shell.execute_reply.started": "2025-02-11T15:43:08.519477Z"
    }
   },
   "outputs": [],
   "source": [
    "for set_type in dataset_types:\n",
    "    get_all_sizes(set_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e8daaf-8cd5-4b04-b35b-54ab85f27879",
   "metadata": {},
   "source": [
    "## Create batch files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b80fabe-f675-4202-8b34-7b22288e619a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:41:15.790931Z",
     "iopub.status.busy": "2025-02-11T15:41:15.790596Z",
     "iopub.status.idle": "2025-02-11T15:41:15.794530Z",
     "shell.execute_reply": "2025-02-11T15:41:15.794108Z",
     "shell.execute_reply.started": "2025-02-11T15:41:15.790915Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dims = {\n",
    "    \"dia_object\": [\"tract\"],\n",
    "    \"dia_source\": [\"tract\"],\n",
    "    \"dia_object_forced_source\": [\"patch\", \"tract\"],\n",
    "    \"object\": [\"tract\"],\n",
    "    \"source\": [\"band\", \"day_obs\", \"physical_filter\", \"visit\"],\n",
    "    \"object_forced_source\": [\"patch\", \"tract\"],\n",
    "}\n",
    "\n",
    "dataset_groupby = {\n",
    "    \"dia_object\": [\"tract\"],\n",
    "    \"dia_source\": [\"tract\"],\n",
    "    \"dia_object_forced_source\": [\"tract\"],\n",
    "    \"object\": [\"tract\"],\n",
    "    \"source\": [\"band\", \"day_obs\"],\n",
    "    \"object_forced_source\": [\"tract\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61c044c-d335-4917-b619-cfee1e24b1af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:53:49.330955Z",
     "iopub.status.busy": "2025-02-11T15:53:49.330581Z",
     "iopub.status.idle": "2025-02-11T15:53:49.334345Z",
     "shell.execute_reply": "2025-02-11T15:53:49.333893Z",
     "shell.execute_reply.started": "2025-02-11T15:53:49.330937Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_index_files(dataset_type):\n",
    "    ref_frame = pd.read_csv(raw_dir / \"sizes\" / f\"{dataset_type}.csv\")\n",
    "    desired_columns = dataset_dims[dataset_type] + [\"path\"]\n",
    "\n",
    "    ref_frame = ref_frame[desired_columns]\n",
    "    groups = ref_frame.groupby(dataset_groupby[dataset_type])\n",
    "    (index_dir / dataset_type).mkdir(parents=True, exist_ok=True)\n",
    "    counter = 0\n",
    "    for _, value in groups:\n",
    "        value.to_csv(index_dir / dataset_type / f\"{counter:03d}.csv\", index=False)\n",
    "        counter += 1\n",
    "    print(\"Wrote\", counter, \"index files for\", dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b95fe11-3718-4753-a441-e721e6ee61db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:53:50.781099Z",
     "iopub.status.busy": "2025-02-11T15:53:50.780764Z",
     "iopub.status.idle": "2025-02-11T15:53:51.681336Z",
     "shell.execute_reply": "2025-02-11T15:53:51.680874Z",
     "shell.execute_reply.started": "2025-02-11T15:53:50.781082Z"
    }
   },
   "outputs": [],
   "source": [
    "for set_type in dataset_types:\n",
    "    write_index_files(set_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b057046-d568-4078-abbb-4887550617bd",
   "metadata": {},
   "source": [
    "## Estimate the pixel thresholds.\n",
    "\n",
    "Using something similar to [this old notebook](https://hats-import.readthedocs.io/en/latest/notebooks/estimate_pixel_threshold.html), but using the full dataset size and row count, we can get a pretty good idea of what good pixel thresholds are for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffbbec98-0694-4786-b505-5ebcb002b976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:54:01.248947Z",
     "iopub.status.busy": "2025-02-11T15:54:01.248612Z",
     "iopub.status.idle": "2025-02-11T15:54:01.252234Z",
     "shell.execute_reply": "2025-02-11T15:54:01.251846Z",
     "shell.execute_reply.started": "2025-02-11T15:54:01.248931Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_import_stats(dataset_type):\n",
    "    all_sizes = pd.read_csv(raw_dir / \"sizes\" / f\"{dataset_type}.csv\")\n",
    "    sample_file_size = all_sizes[\"file_size\"].sum()\n",
    "    num_rows = all_sizes[\"num_rows\"].sum()\n",
    "\n",
    "    ## 300MB\n",
    "    ideal_file_small = 300 * 1024 * 1024\n",
    "    ## 1G\n",
    "    ideal_file_large = 1024 * 1024 * 1024\n",
    "\n",
    "    threshold_small = ideal_file_small / sample_file_size * num_rows\n",
    "    threshold_large = ideal_file_large / sample_file_size * num_rows\n",
    "\n",
    "    print(dataset_type)\n",
    "    print(f\"  threshold between {int(threshold_small):_} and {int(threshold_large):_}\")\n",
    "    print(f'  total size_on_disk: {all_sizes[\"gbs\"].sum():.2f} G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5412b1b9-054b-40cf-afc3-e1d89ea53519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:54:02.083200Z",
     "iopub.status.busy": "2025-02-11T15:54:02.082815Z",
     "iopub.status.idle": "2025-02-11T15:54:02.143657Z",
     "shell.execute_reply": "2025-02-11T15:54:02.143251Z",
     "shell.execute_reply.started": "2025-02-11T15:54:02.083183Z"
    }
   },
   "outputs": [],
   "source": [
    "for set_type in dataset_types:\n",
    "    print_import_stats(set_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
